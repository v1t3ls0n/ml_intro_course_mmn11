{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "\n",
    "# Load and preprocess the MNIST dataset.\n",
    "X, y = load_mnist()\n",
    "X = preprocess_data(X)\n",
    "\n",
    "# Split data: first 60,000 for training, last 10,000 for testing.\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "# Further split the training set to obtain a validation set for plotting loss curves.\n",
    "X_train_main, X_val = X_train[:-5000], X_train[-5000:]\n",
    "y_train_main, y_val = y_train[:-5000], y_train[-5000:]\n",
    "\n",
    "# Initialize and train the multi-class perceptron.\n",
    "mcp = MultiClassPerceptron(learning_rate=0.01, max_iter=1000)\n",
    "mcp.fit(X_train_main, y_train_main, X_val, y_val)\n",
    "\n",
    "# Evaluate the model on the test set.\n",
    "prebuilt_cm, accuracy = evaluate_model(mcp, X_test, y_test)\n",
    "\n",
    "# Plot the prebuilt confusion matrix.\n",
    "plot_confusion_matrix(prebuilt_cm)\n",
    "\n",
    "# Plot training and validation loss curves for the binary classifier distinguishing digit 0.\n",
    "train_losses, val_losses = mcp.loss_history[0]\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
    "if val_losses:\n",
    "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Misclassification Count\")\n",
    "plt.title(\"Loss Curves for Classifier (Digit 0 vs. Rest)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
