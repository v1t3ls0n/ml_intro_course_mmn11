{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v1t3ls0n/ml_intro_course_mmn11/blob/main/notebooks/guyvitelson_mmn11_ml_latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztlf-kRcUjIz"
      },
      "source": [
        "# ממן 11 - מבוא ללמידה חישובית - סמסטר 2025ב - גיא ויטלזון 203379706"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXiZOQmO5Tak"
      },
      "source": [
        "##**If you run this within Google Collab, Dont Worry!**\n",
        "all the missing python files/directories/modules will be automatically feteched from my github repository\n",
        "\n",
        "**My GitHub Profile** : https://github.com/v1t3ls0n\n",
        "\n",
        "**The Repository:** https://github.com/v1t3ls0n/ml_intro_course_mmn11\n",
        "\n",
        "**Student ID:** 203379706"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqLIUat1dEr2"
      },
      "source": [
        "## Fetch Resources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmauUwgLR-mx"
      },
      "source": [
        "### External Code Imports (pip packages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xUkaAHQFR-mx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np # type: ignore\n",
        "import matplotlib.pyplot as plt # type: ignore\n",
        "import seaborn as sns # type: ignore\n",
        "import time\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlMUAQraR-my"
      },
      "source": [
        "### Fetch Missing Files For Google Colab Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "msKnbktXR-my"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %%capture run_output\n",
        "# %matplotlib inline\n",
        "\n",
        "if sys.platform != 'win32': # check if we are running on google collab\n",
        "  repo_url = \"https://github.com/v1t3ls0n/ml_intro_course_mmn11\"\n",
        "  repo_name = \"ml_intro_course_mmn11\"\n",
        "  from tqdm.notebook import tqdm # type: ignore\n",
        "\n",
        "\n",
        "  # Clone the repository if it doesn't exist\n",
        "  if not os.path.exists(repo_name):\n",
        "    os.system(f\"git clone {repo_url}\")\n",
        "\n",
        "  # Construct the path to the repository directory\n",
        "  repo_path = os.path.join(os.getcwd(), repo_name)\n",
        "\n",
        "  # Add the repository directory to the Python path\n",
        "  if repo_path not in sys.path:\n",
        "    sys.path.insert(0, repo_path)\n",
        "\n",
        "  # --- Extract 'core' and 'notebooks' directories ---\n",
        "  def extract_directories(source_dir, destination_dir, dir_names):\n",
        "      for dir_name in dir_names:\n",
        "          source_path = os.path.join(source_dir, dir_name)\n",
        "          destination_path = os.path.join(destination_dir, dir_name)\n",
        "          if os.path.exists(source_path):\n",
        "              shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
        "\n",
        "  destination_path = \".\"\n",
        "  # Extract the directories\n",
        "  extract_directories(repo_path, destination_path, [\"core\"])\n",
        "  project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "  sys.path.insert(0, project_root)\n",
        "  if os.path.exists(\"ml_intro_course_mmn11\"):\n",
        "    shutil.rmtree(\"ml_intro_course_mmn11\")\n",
        "  if os.path.exists(\"sample_data\"):\n",
        "    shutil.rmtree(\"sample_data\")\n",
        "else:\n",
        "  from tqdm import tqdm  # type: ignore\n",
        "  current_dir = os.getcwd()  # Current working directory\n",
        "  project_root = os.path.abspath(os.path.join(current_dir, '..'))  # Root directory of the project\n",
        "  sys.path.insert(0, project_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYrRE0dcR-my"
      },
      "source": [
        "### Internal Code Imports (original code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VTaL_MsqeE00"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ========== Internal Code Imports ==========\n",
        "\n",
        "#Logger\n",
        "from core.logger.config import logger\n",
        "\n",
        "# Data Preprocessing\n",
        "from core.data.mnist_loader import load_mnist\n",
        "from core.data.data_preprocessing import preprocess_data\n",
        "\n",
        "# Models\n",
        "from core.models.perceptron.multi_class_perceptron import MultiClassPerceptron\n",
        "from core.models.logistic_regression.softmax_lregression import SoftmaxRegression\n",
        "from core.models.linear_regression.linear_regression import  LinearRegression\n",
        "\n",
        "# Performance & Plotting\n",
        "from core.analysis.evaluation_functions import (\n",
        "    evaluate_model,\n",
        "    aggregate_iteration_losses,\n",
        "    aggregate_iteration_losses_softmax\n",
        ")\n",
        "\n",
        "from core.analysis.plotting import (\n",
        "    plot_confusion_matrix_annotated,\n",
        "    plot_error_curves,\n",
        "    plot_accuracy_vs_max_iter,\n",
        "    plot_runtime_vs_max_iter,\n",
        "    plot_performance_summary_extended,\n",
        "    plot_train_curves_three_models,\n",
        "    plot_metric_vs_learning_rate,\n",
        "    plot_accuracy_vs_max_iter_4models,\n",
        "    plot_runtime_vs_max_iter_4models,\n",
        "    plot_accuracy_vs_runtime,\n",
        "    plot_performance_summary_extended_by_runtime,\n",
        "    plot_performance_summary_4models_by_runtime,\n",
        "    plot_accuracy_vs_runtime_4models\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(\"MyGlobalLogger\") # configured in core/logger/config.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKs0r5ROHxuY"
      },
      "source": [
        "# Overview\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWMyo4jnR-mx"
      },
      "source": [
        "## MNIST Digit Classification Using Perceptron Learning Algorithm (PLA)\n",
        "\n",
        "**Objective:**  \n",
        "This notebook compares the performance of two variants of the Perceptron Learning Algorithm (PLA) on the MNIST digit classification task:\n",
        "- **Clean PLA:** Standard perceptron without enhancements.\n",
        "- **Pocket PLA:** Enhanced perceptron that stores the best-performing weights during training (using the Pocket algorithm).\n",
        "\n",
        "**Dataset:**  \n",
        "- MNIST dataset consisting of 60,000 training samples and 10,000 test samples.\n",
        "- The images are normalized to the range [0, 1] and a bias term is added, resulting in input samples with 785 features.\n",
        "\n",
        "**Evaluation Metrics:**  \n",
        "- **Confusion Matrices:** Provides a detailed view of how well each digit is classified.\n",
        "- **Overall Accuracy (ACC):** Defined as \\(\\text{ACC} = \\frac{TP + TN}{TP + TN + FP + FN}\\).\n",
        "- **Sensitivity (True Positive Rate, TPR):** For each digit, calculated as \\(\\text{TPR} = \\frac{TP}{TP + FN}\\), showing the model’s ability to correctly identify the digit.\n",
        "- **Selectivity (Specificity, TNR):** For each digit, calculated as \\(\\text{TNR} = \\frac{TN}{TN + FP}\\), showing the model’s ability to correctly identify negatives.\n",
        "- **Training and Testing Error Curves:** Visualized as a function of iteration for detailed analysis of learning dynamics.\n",
        "- **Runtime:** The time taken to train the models.\n",
        "\n",
        "**Goals:**  \n",
        "- Evaluate and compare the model accuracy and robustness between Clean PLA and Pocket PLA.\n",
        "- Analyze and visualize the performance through confusion matrices, error curves, and summary plots (accuracy, sensitivity, selectivity, and runtime vs. the number of iterations).\n",
        "- Provide a comprehensive discussion on how training iterations affect the decision boundaries and the overall performance, particularly in the one-vs-all classification setup.\n",
        "\n",
        "This notebook integrates detailed quantitative evaluation with comprehensive visualizations to thoroughly analyze the multi-class Perceptron performance on the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keDSGERzwvrB"
      },
      "source": [
        "# Choose Run Parameters **(Significant Effect On Model's Runtime!)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNJHO7mQrANq"
      },
      "outputs": [],
      "source": [
        "#######################################################################\n",
        "# SEPARATE RUN PARAMETERS FOR PERCEPTRONS vs. REGRESSIONS\n",
        "#######################################################################\n",
        "\n",
        "# Perceptrons (Clean & Pocket) iteration-based run\n",
        "perceptron_max_iter_values = [20,50,100,1000]  # for Clean PLA & Pocket PLA\n",
        "# Logging the run parameters\n",
        "logger.info(f\"=== Perceptron Run Parameters ===\")\n",
        "logger.info(f\"max_iter_values = {perceptron_max_iter_values}\")\n",
        "\n",
        "\n",
        "# Regression (Softmax & Linear) run parameters.\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001]  # for Softmax & Linear Regression\n",
        "iteration_counts = [100,1000,10000]\n",
        "regression_run_configs = [\n",
        "    {\n",
        "        \"label\": f\"LR={lr}/Iter={it}\",\n",
        "        \"learning_rate\": lr,\n",
        "        \"max_iter\": it\n",
        "    }\n",
        "    for lr in learning_rates\n",
        "    for it in iteration_counts\n",
        "]\n",
        "\n",
        "logger.info(f\"=== Regression Run Parameters ===\")\n",
        "for cfg in regression_run_configs:\n",
        "    logger.info(f\"{cfg['label']} -> learning_rate={cfg['learning_rate']}, max_iter={cfg['max_iter']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e73BoKY7cmJU"
      },
      "source": [
        "# Load and Preprocess the MNIST Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osGLi3Hic5qW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We'll load the MNIST dataset using our custom loader (`mnist_loader`) and then apply preprocessing (`data_preprocessing`).\n",
        "The preprocessing step normalizes each image to the range [0, 1] and adds a bias term, resulting in input samples with 785 features.\n",
        "This setup ensures that the training set contains 60,000 samples and the test set 10,000 samples, preparing the data for the subsequent classification tasks.\n",
        "'''\n",
        "\n",
        "# New section\n",
        "# Load raw MNIST data (X: images, y: labels)\n",
        "X_raw, y_raw = load_mnist()\n",
        "\n",
        "\n",
        "logger.info(\"Raw MNIST data shapes: X_raw: %s, y_raw: %s\", X_raw.shape, y_raw.shape)\n",
        "\n",
        "# Preprocess (normalize & add bias = True)\n",
        "X = preprocess_data(X_raw, add_bias=True, normalize=True)\n",
        "logger.info(\"Preprocessed shape: %s\", X.shape)\n",
        "\n",
        "# Split into train/test manually or with 60k/10k as the task suggests\n",
        "X_train, y_train = X[:60000], y_raw[:60000]\n",
        "X_test,  y_test  = X[60000:], y_raw[60000:]\n",
        "\n",
        "logger.info(\"Train set: X_train: %s, y_train: %s\", X_train.shape, y_train.shape)\n",
        "logger.info(\"Test set: X_test: %s, y_test: %s\", X_test.shape, y_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O4hrMBCejtr"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sik1JDX6Hxub"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# TRAINING CELL\n",
        "# =========================================================\n",
        "\n",
        "# 1) Dictionaries to store trained models\n",
        "trained_models_clean   = {}\n",
        "trained_models_pocket  = {}\n",
        "trained_models_softmax = {}\n",
        "trained_models_linear  = {}\n",
        "\n",
        "# 2) Train Regression Models (Softmax & Linear)\n",
        "logger.info(\"=== TRAINING REGRESSION MODELS (Softmax & Linear) ===\")\n",
        "for cfg in tqdm(regression_run_configs, desc=\"Train Regressions\"):\n",
        "    lr_val = cfg[\"learning_rate\"]\n",
        "    max_iter_val = cfg[\"max_iter\"]\n",
        "    label = cfg[\"label\"]  # e.g. \"LR=0.001/Iter=1000\"\n",
        "\n",
        "    # --- Softmax ---\n",
        "    logger.info(f\"--- Softmax {label} ---\")\n",
        "    s_model = SoftmaxRegression(\n",
        "        num_classes=10,\n",
        "        max_iter=max_iter_val,\n",
        "        learning_rate=lr_val,\n",
        "        adaptive_lr=True\n",
        "    )\n",
        "    s_model.fit(X_train, y_train)\n",
        "    trained_models_softmax[(lr_val, max_iter_val)] = s_model\n",
        "\n",
        "    # --- Linear ---\n",
        "    logger.info(f\"--- Linear Regression {label} ---\")\n",
        "    lin_model = LinearRegression(\n",
        "        num_classes=10,\n",
        "        max_iter=max_iter_val,\n",
        "        learning_rate=lr_val,\n",
        "        adaptive_lr=True,\n",
        "        early_stopping=False\n",
        "    )\n",
        "    lin_model.fit(X_train, y_train)\n",
        "    trained_models_linear[(lr_val, max_iter_val)] = lin_model\n",
        "\n",
        "logger.info(\"Training complete for Softmax and Linear.\")\n",
        "\n",
        "# 3) Train Perceptron Models (Clean & Pocket)\n",
        "logger.info(\"=== TRAINING PERCEPTRON MODELS (Clean & Pocket) ===\")\n",
        "for max_iter in tqdm(perceptron_max_iter_values, desc=\"Train Clean & Pocket\"):\n",
        "    logger.info(f\"--- Clean PLA, max_iter={max_iter} ---\")\n",
        "    clean_perc = MultiClassPerceptron(num_classes=10, max_iter=max_iter, use_pocket=False)\n",
        "    clean_perc.fit(X_train, y_train)\n",
        "    trained_models_clean[max_iter] = clean_perc\n",
        "\n",
        "    logger.info(f\"--- Pocket PLA, max_iter={max_iter} ---\")\n",
        "    pocket_perc = MultiClassPerceptron(num_classes=10, max_iter=max_iter, use_pocket=True)\n",
        "    pocket_perc.fit(X_train, y_train)\n",
        "    trained_models_pocket[max_iter] = pocket_perc\n",
        "\n",
        "logger.info(\"Training complete for Clean PLA and Pocket PLA.\")\n",
        "logger.info(\"=== ALL TRAINING COMPLETE ===\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VepUzPkWrANq"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hech6_lrANq"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "# EVALUATION CELL (with pandas DataFrame)\n",
        "##################################################\n",
        "\n",
        "\n",
        "# 1) Evaluate Perceptrons: Clean & Pocket\n",
        "accuracies_clean, accuracies_pocket = [], []\n",
        "runtimes_clean,   runtimes_pocket   = [], []\n",
        "sensitivities_clean, sensitivities_pocket = [], []\n",
        "selectivities_clean, selectivities_pocket = [], []\n",
        "\n",
        "conf_clean, conf_pocket = [], []\n",
        "meta_clean, meta_pocket = [], []\n",
        "\n",
        "for max_iter in tqdm(perceptron_max_iter_values, desc=\"Evaluate Clean & Pocket\"):\n",
        "    # === Evaluate Clean PLA ===\n",
        "    c_model = trained_models_clean[max_iter]\n",
        "    cm_c, acc_c, s_c, sp_c, rt_c, ex_c = evaluate_model(\n",
        "        c_model, X_test, y_test, classes=range(10), model_name=\"Clean PLA\"\n",
        "    )\n",
        "    accuracies_clean.append(acc_c)\n",
        "    runtimes_clean.append(rt_c)\n",
        "    sensitivities_clean.append(np.mean(s_c))\n",
        "    selectivities_clean.append(np.mean(sp_c))\n",
        "    conf_clean.append(cm_c)\n",
        "\n",
        "    cdict = {\n",
        "        \"max_iter\": max_iter,\n",
        "        \"accuracy\": acc_c,\n",
        "        \"runtime\": rt_c,\n",
        "        \"avg_sensitivity\": np.mean(s_c),\n",
        "        \"avg_selectivity\": np.mean(sp_c),\n",
        "        \"method\": \"Clean PLA\"\n",
        "    }\n",
        "    cdict.update(ex_c)\n",
        "    meta_clean.append(cdict)\n",
        "\n",
        "    # === Evaluate Pocket PLA ===\n",
        "    p_model = trained_models_pocket[max_iter]\n",
        "    cm_p, acc_p, s_p, sp_p, rt_p, ex_p = evaluate_model(\n",
        "        p_model, X_test, y_test, classes=range(10), model_name=\"Pocket PLA\"\n",
        "    )\n",
        "    accuracies_pocket.append(acc_p)\n",
        "    runtimes_pocket.append(rt_p)\n",
        "    sensitivities_pocket.append(np.mean(s_p))\n",
        "    selectivities_pocket.append(np.mean(sp_p))\n",
        "    conf_pocket.append(cm_p)\n",
        "\n",
        "    pdict = {\n",
        "        \"max_iter\": max_iter,\n",
        "        \"accuracy\": acc_p,\n",
        "        \"runtime\": rt_p,\n",
        "        \"avg_sensitivity\": np.mean(s_p),\n",
        "        \"avg_selectivity\": np.mean(sp_p),\n",
        "        \"method\": \"Pocket PLA\"\n",
        "    }\n",
        "    pdict.update(ex_p)\n",
        "    meta_pocket.append(pdict)\n",
        "\n",
        "# Aggregated iteration-level training curves for Perceptrons\n",
        "clean_train_curve = aggregate_iteration_losses(\n",
        "    [trained_models_clean[m] for m in perceptron_max_iter_values]\n",
        ")\n",
        "pocket_train_curve = aggregate_iteration_losses(\n",
        "    [trained_models_pocket[m] for m in perceptron_max_iter_values]\n",
        ")\n",
        "\n",
        "# 2) Evaluate Regression Models: Softmax & Linear\n",
        "accuracies_softmax = []\n",
        "runtimes_softmax   = []\n",
        "sensitivities_soft = []\n",
        "selectivities_soft = []\n",
        "conf_soft          = []\n",
        "meta_soft          = []\n",
        "\n",
        "accuracies_linear = []\n",
        "runtimes_linear   = []\n",
        "sensitivities_lin = []\n",
        "selectivities_lin = []\n",
        "conf_linear       = []\n",
        "meta_linear       = []\n",
        "\n",
        "for cfg in tqdm(regression_run_configs, desc=\"Evaluate Regressions\"):\n",
        "    lr_val = cfg[\"learning_rate\"]\n",
        "    max_iter_val = cfg[\"max_iter\"]\n",
        "    label = cfg[\"label\"]\n",
        "\n",
        "    # === Evaluate Softmax ===\n",
        "    s_model = trained_models_softmax[(lr_val, max_iter_val)]\n",
        "    cm_s, a_s, se_s, sp_s, r_s, ex_s = evaluate_model(\n",
        "        s_model, X_test, y_test, classes=range(10),\n",
        "        model_name=f\"Softmax ({label})\"\n",
        "    )\n",
        "    accuracies_softmax.append(a_s)\n",
        "    runtimes_softmax.append(r_s)\n",
        "    sensitivities_soft.append(np.mean(se_s))\n",
        "    selectivities_soft.append(np.mean(sp_s))\n",
        "    conf_soft.append(cm_s)\n",
        "\n",
        "    ms = {\n",
        "        \"label\": label,\n",
        "        \"learning_rate\": lr_val,\n",
        "        \"max_iter\": max_iter_val,\n",
        "        \"accuracy\": a_s,\n",
        "        \"runtime\": r_s,\n",
        "        \"avg_sensitivity\": np.mean(se_s),\n",
        "        \"avg_selectivity\": np.mean(sp_s),\n",
        "        \"method\": \"Softmax\"\n",
        "    }\n",
        "    ms.update(ex_s)\n",
        "    meta_soft.append(ms)\n",
        "\n",
        "    # === Evaluate Linear ===\n",
        "    lin_model = trained_models_linear[(lr_val, max_iter_val)]\n",
        "    cm_l, a_l, se_l, sp_l, r_l, ex_l = evaluate_model(\n",
        "        lin_model, X_test, y_test, classes=range(10),\n",
        "        model_name=f\"Linear ({label})\"\n",
        "    )\n",
        "    accuracies_linear.append(a_l)\n",
        "    runtimes_linear.append(r_l)\n",
        "    sensitivities_lin.append(np.mean(se_l))\n",
        "    selectivities_lin.append(np.mean(sp_l))\n",
        "    conf_linear.append(cm_l)\n",
        "\n",
        "    ml = {\n",
        "        \"label\": label,\n",
        "        \"learning_rate\": lr_val,\n",
        "        \"max_iter\": max_iter_val,\n",
        "        \"accuracy\": a_l,\n",
        "        \"runtime\": r_l,\n",
        "        \"avg_sensitivity\": np.mean(se_l),\n",
        "        \"avg_selectivity\": np.mean(sp_l),\n",
        "        \"method\": \"Linear Regression\"\n",
        "    }\n",
        "    ml.update(ex_l)\n",
        "    meta_linear.append(ml)\n",
        "\n",
        "\n",
        "logger.info(\"Evaluation complete for Perceptrons & Regressions.\")\n",
        "\n",
        "\n",
        "# # 1) Build the DataFrame of all model results\n",
        "# all_rows = []\n",
        "\n",
        "# # A) Clean PLA\n",
        "# for i, max_iter in tqdm(\n",
        "#     enumerate(perceptron_max_iter_values),\n",
        "#     desc=\"Collecting Clean PLA\",\n",
        "#     total=len(perceptron_max_iter_values)\n",
        "# ):\n",
        "#     all_rows.append({\n",
        "#         'model': 'Clean PLA',\n",
        "#         'max_iter': max_iter,\n",
        "#         'runtime': runtimes_clean[i],\n",
        "#         'accuracy': accuracies_clean[i],\n",
        "#         'sensitivity': sensitivities_clean[i],\n",
        "#         'selectivity': selectivities_clean[i]\n",
        "#     })\n",
        "\n",
        "# # B) Pocket PLA\n",
        "# for i, max_iter in tqdm(\n",
        "#     enumerate(perceptron_max_iter_values),\n",
        "#     desc=\"Collecting Pocket PLA\",\n",
        "#     total=len(perceptron_max_iter_values)\n",
        "# ):\n",
        "#     all_rows.append({\n",
        "#         'model': 'Pocket PLA',\n",
        "#         'max_iter': max_iter,\n",
        "#         'runtime': runtimes_pocket[i],\n",
        "#         'accuracy': accuracies_pocket[i],\n",
        "#         'sensitivity': sensitivities_pocket[i],\n",
        "#         'selectivity': selectivities_pocket[i]\n",
        "#     })\n",
        "\n",
        "# # C) Softmax\n",
        "# for i, row_meta in tqdm(\n",
        "#     enumerate(meta_soft),\n",
        "#     desc=\"Collecting Softmax\",\n",
        "#     total=len(meta_soft)\n",
        "# ):\n",
        "#     all_rows.append({\n",
        "#         'model': 'Softmax',\n",
        "#         'max_iter': row_meta['max_iter'],\n",
        "#         'runtime': runtimes_softmax[i],\n",
        "#         'accuracy': accuracies_softmax[i],\n",
        "#         'sensitivity': sensitivities_soft[i],\n",
        "#         'selectivity': selectivities_soft[i]\n",
        "#     })\n",
        "\n",
        "# # D) Linear\n",
        "# for i, row_meta in tqdm(\n",
        "#     enumerate(meta_linear),\n",
        "#     desc=\"Collecting Linear\",\n",
        "#     total=len(meta_linear)\n",
        "# ):\n",
        "#     all_rows.append({\n",
        "#         'model': 'Linear',\n",
        "#         'max_iter': row_meta['max_iter'],\n",
        "#         'runtime': runtimes_linear[i],\n",
        "#         'accuracy': accuracies_linear[i],\n",
        "#         'sensitivity': sensitivities_lin[i],\n",
        "#         'selectivity': selectivities_lin[i]\n",
        "#     })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwCAybO5owmg"
      },
      "source": [
        "# Visualize (Generate Plots, Confusion Matricies, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC4vaIjVowmg"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tqdm import tqdm\n",
        "\n",
        "##################################################\n",
        "# 1) CREATE A SINGLE PANDAS DATAFRAME FOR ALL RESULTS\n",
        "##################################################\n",
        "all_rows = []\n",
        "\n",
        "# (A) Clean PLA\n",
        "for i, max_iter in tqdm(\n",
        "    enumerate(perceptron_max_iter_values),\n",
        "    desc=\"Collecting Clean PLA\",\n",
        "    total=len(perceptron_max_iter_values)\n",
        "):\n",
        "    all_rows.append({\n",
        "        'model': 'Clean PLA',\n",
        "        'max_iter': max_iter,\n",
        "        'runtime': runtimes_clean[i],\n",
        "        'accuracy': accuracies_clean[i],\n",
        "        'sensitivity': sensitivities_clean[i],\n",
        "        'selectivity': selectivities_clean[i]\n",
        "    })\n",
        "\n",
        "# (B) Pocket PLA\n",
        "for i, max_iter in tqdm(\n",
        "    enumerate(perceptron_max_iter_values),\n",
        "    desc=\"Collecting Pocket PLA\",\n",
        "    total=len(perceptron_max_iter_values)\n",
        "):\n",
        "    all_rows.append({\n",
        "        'model': 'Pocket PLA',\n",
        "        'max_iter': max_iter,\n",
        "        'runtime': runtimes_pocket[i],\n",
        "        'accuracy': accuracies_pocket[i],\n",
        "        'sensitivity': sensitivities_pocket[i],\n",
        "        'selectivity': selectivities_pocket[i]\n",
        "    })\n",
        "\n",
        "# (C) Softmax\n",
        "for i, row_meta in tqdm(\n",
        "    enumerate(meta_soft),\n",
        "    desc=\"Collecting Softmax\",\n",
        "    total=len(meta_soft)\n",
        "):\n",
        "    all_rows.append({\n",
        "        'model': 'Softmax',\n",
        "        'max_iter': row_meta['max_iter'],\n",
        "        'runtime': runtimes_softmax[i],\n",
        "        'accuracy': accuracies_softmax[i],\n",
        "        'sensitivity': sensitivities_soft[i],\n",
        "        'selectivity': selectivities_soft[i]\n",
        "    })\n",
        "\n",
        "# (D) Linear\n",
        "for i, row_meta in tqdm(\n",
        "    enumerate(meta_linear),\n",
        "    desc=\"Collecting Linear\",\n",
        "    total=len(meta_linear)\n",
        "):\n",
        "    all_rows.append({\n",
        "        'model': 'Linear',\n",
        "        'max_iter': row_meta['max_iter'],\n",
        "        'runtime': runtimes_linear[i],\n",
        "        'accuracy': accuracies_linear[i],\n",
        "        'sensitivity': sensitivities_lin[i],\n",
        "        'selectivity': selectivities_lin[i]\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(all_rows)\n",
        "logger.info(\"Combined Results DataFrame:\\n%s\", df_results)\n",
        "display(df_results.head(20))\n",
        "\n",
        "############################################################################\n",
        "# 2) CONFUSION MATRICES FOR ALL MODELS (GROUPED BY PLOT TYPE)\n",
        "############################################################################\n",
        "\n",
        "logger.info(\"=== Plotting ALL Confusion Matrices ===\")\n",
        "\n",
        "# 2A) Perceptron: Clean\n",
        "for idx, meta in tqdm(enumerate(meta_clean), total=len(meta_clean), desc=\"Confusions: Clean PLA\"):\n",
        "    title = f\"Clean PLA (max_iter={meta['max_iter']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
        "    plot_confusion_matrix_annotated(\n",
        "        conf_clean[idx],\n",
        "        classes=range(10),\n",
        "        title=title,\n",
        "        method=meta[\"method\"],\n",
        "        max_iter=meta[\"max_iter\"]\n",
        "    )\n",
        "\n",
        "# 2B) Perceptron: Pocket\n",
        "for idx, meta in tqdm(enumerate(meta_pocket), total=len(meta_pocket), desc=\"Confusions: Pocket PLA\"):\n",
        "    title = f\"Pocket PLA (max_iter={meta['max_iter']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
        "    plot_confusion_matrix_annotated(\n",
        "        conf_pocket[idx],\n",
        "        classes=range(10),\n",
        "        title=title,\n",
        "        method=meta[\"method\"],\n",
        "        max_iter=meta[\"max_iter\"]\n",
        "    )\n",
        "\n",
        "# 2C) Softmax\n",
        "for idx, meta in tqdm(enumerate(meta_soft), total=len(meta_soft), desc=\"Confusions: Softmax\"):\n",
        "    title = f\"Softmax ({meta['label']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
        "    plot_confusion_matrix_annotated(\n",
        "        conf_soft[idx],\n",
        "        classes=range(10),\n",
        "        title=title,\n",
        "        method=meta[\"method\"],\n",
        "        max_iter=meta[\"max_iter\"]\n",
        "    )\n",
        "\n",
        "# 2D) Linear\n",
        "for idx, meta in tqdm(enumerate(meta_linear), total=len(meta_linear), desc=\"Confusions: Linear\"):\n",
        "    title = f\"Linear ({meta['label']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
        "    plot_confusion_matrix_annotated(\n",
        "        conf_linear[idx],\n",
        "        classes=range(10),\n",
        "        title=title,\n",
        "        method=meta[\"method\"],\n",
        "        max_iter=meta[\"max_iter\"]\n",
        "    )\n",
        "\n",
        "\n",
        "############################################################################\n",
        "# 3) ITERATION-LEVEL PLOTS (ALL MODELS)\n",
        "############################################################################\n",
        "\n",
        "logger.info(\"=== Iteration-Level Visualization (All Models) ===\")\n",
        "\n",
        "# 3A) Perceptron: Clean & Pocket\n",
        "for max_iter, c_model in trained_models_clean.items():\n",
        "    df_iter = c_model.get_iteration_df()\n",
        "    if not df_iter.empty and \"train_error\" in df_iter.columns:\n",
        "        title = f\"Clean PLA max_iter={max_iter}: Train Error vs. Iteration\"\n",
        "        df_iter.plot(x=\"iteration\", y=\"train_error\", marker='o', figsize=(8,5), title=title)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "for max_iter, p_model in trained_models_pocket.items():\n",
        "    df_iter = p_model.get_iteration_df()\n",
        "    if not df_iter.empty and \"train_error\" in df_iter.columns:\n",
        "        title = f\"Pocket PLA max_iter={max_iter}: Train Error vs. Iteration\"\n",
        "        df_iter.plot(x=\"iteration\", y=\"train_error\", marker='o', figsize=(8,5), title=title)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "# 3B) Softmax\n",
        "for (lr_val, max_iter_val), s_model in trained_models_softmax.items():\n",
        "    df_iter = s_model.get_iteration_df()  # Must be implemented in your SoftmaxRegression\n",
        "    if not df_iter.empty:\n",
        "        title = f\"Softmax LR={lr_val}, max_iter={max_iter_val}: Train Loss vs. Iteration\"\n",
        "        df_iter.plot(x=\"iteration\", y=\"train_loss\", marker='o', figsize=(8,5), title=title)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        if \"test_loss\" in df_iter.columns:\n",
        "            title = f\"Softmax LR={lr_val}, max_iter={max_iter_val}: Train & Test Loss\"\n",
        "            df_iter.plot(x=\"iteration\", y=[\"train_loss\",\"test_loss\"], marker='o', figsize=(8,5), title=title)\n",
        "            plt.grid(True, linestyle='--', alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "        if \"avg_adaptive_lr\" in df_iter.columns:\n",
        "            title = f\"Softmax LR={lr_val}, max_iter={max_iter_val}: Avg Adaptive LR vs. Iteration\"\n",
        "            df_iter.plot(x=\"iteration\", y=\"avg_adaptive_lr\", marker='x', figsize=(8,5), title=title)\n",
        "            plt.grid(True, linestyle='--', alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "# 3C) Linear\n",
        "for (lr_val, max_iter_val), lin_model in trained_models_linear.items():\n",
        "    df_iter = lin_model.get_iteration_df()  # Must be implemented in your LinearRegression\n",
        "    if not df_iter.empty:\n",
        "        title = f\"Linear LR={lr_val}, max_iter={max_iter_val}: Train Loss vs. Iteration\"\n",
        "        df_iter.plot(x=\"iteration\", y=\"train_loss\", marker='o', figsize=(8,5), title=title)\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        if \"test_loss\" in df_iter.columns:\n",
        "            title = f\"Linear LR={lr_val}, max_iter={max_iter_val}: Train & Test Loss\"\n",
        "            df_iter.plot(x=\"iteration\", y=[\"train_loss\",\"test_loss\"], marker='o', figsize=(8,5), title=title)\n",
        "            plt.grid(True, linestyle='--', alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "        if \"avg_adaptive_lr\" in df_iter.columns:\n",
        "            title = f\"Linear LR={lr_val}, max_iter={max_iter_val}: Avg Adaptive LR vs. Iteration\"\n",
        "            df_iter.plot(x=\"iteration\", y=\"avg_adaptive_lr\", marker='x', figsize=(8,5), title=title)\n",
        "            plt.grid(True, linestyle='--', alpha=0.7)\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "############################################################################\n",
        "# 4) PANDAS + SEABORN PLOTS\n",
        "############################################################################\n",
        "\n",
        "logger.info(\"=== Pandas + Seaborn Plots ===\")\n",
        "\n",
        "# 4A) LINE PLOT: Accuracy vs. max_iter (Perceptrons Only)\n",
        "df_perc = df_results[df_results['model'].isin(['Clean PLA','Pocket PLA'])].copy()\n",
        "df_perc.sort_values(['model','max_iter'], inplace=True)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.lineplot(\n",
        "    data=df_perc,\n",
        "    x='max_iter', y='accuracy',\n",
        "    hue='model', marker='o'\n",
        ")\n",
        "plt.title(\"Perceptrons: Accuracy vs. max_iter (Pandas/Seaborn)\")\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# 4B) BAR CHART: Average Accuracy by Model\n",
        "df_mean = df_results.groupby('model', as_index=False)['accuracy'].mean()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(data=df_mean, x='model', y='accuracy')\n",
        "plt.title(\"Average Accuracy by Model (Pandas/Seaborn)\")\n",
        "plt.ylim(0.7, 1.0)\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# 4C) SCATTER PLOT: Accuracy vs. Runtime, colored by model\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(\n",
        "    data=df_results,\n",
        "    x='runtime', y='accuracy',\n",
        "    hue='model', style='model',\n",
        "    s=100\n",
        ")\n",
        "plt.title(\"Accuracy vs. Runtime (All Models) (Pandas/Seaborn)\")\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "############################################################################\n",
        "# 5) CUSTOM SUMMARY PLOTS (AGGREGATED CURVES, ETC.)\n",
        "############################################################################\n",
        "\n",
        "logger.info(\"=== Custom Summaries (Aggregated Curves, etc.) ===\")\n",
        "\n",
        "# 5A) Aggregated Perceptron Curves\n",
        "plot_train_curves_three_models(\n",
        "    clean_train_curve=clean_train_curve,\n",
        "    pocket_train_curve=pocket_train_curve,\n",
        "    softmax_train_curve=None,  # no Softmax aggregator\n",
        "    title=\"Aggregated Perceptron Train Curves (Clean vs. Pocket)\",\n",
        "    max_iter=perceptron_max_iter_values[-1]\n",
        ")\n",
        "\n",
        "# 5B) Summaries for Perceptron\n",
        "plot_accuracy_vs_max_iter(\n",
        "    max_iter_values=perceptron_max_iter_values,\n",
        "    accuracies_clean=accuracies_clean,\n",
        "    accuracies_pocket=accuracies_pocket,\n",
        "    accuracies_softmax=None\n",
        ")\n",
        "\n",
        "plot_runtime_vs_max_iter(\n",
        "    max_iter_values=perceptron_max_iter_values,\n",
        "    runtimes_clean=runtimes_clean,\n",
        "    runtimes_pocket=runtimes_pocket,\n",
        "    runtimes_softmax=None\n",
        ")\n",
        "\n",
        "plot_accuracy_vs_runtime(\n",
        "    runtimes_clean=runtimes_clean,\n",
        "    accuracies_clean=accuracies_clean,\n",
        "    runtimes_pocket=runtimes_pocket,\n",
        "    accuracies_pocket=accuracies_pocket,\n",
        "    title=\"Perceptrons: Accuracy vs. Runtime\"\n",
        ")\n",
        "\n",
        "plot_performance_summary_extended_by_runtime(\n",
        "    runtimes_clean=runtimes_clean,\n",
        "    accuracies_clean=accuracies_clean,\n",
        "    sensitivities_clean=sensitivities_clean,\n",
        "    selectivities_clean=selectivities_clean,\n",
        "    runtimes_pocket=runtimes_pocket,\n",
        "    accuracies_pocket=accuracies_pocket,\n",
        "    sensitivities_pocket=sensitivities_pocket,\n",
        "    selectivities_pocket=selectivities_pocket,\n",
        "    title=\"Perceptrons: Performance vs. Runtime\"\n",
        ")\n",
        "\n",
        "# 5C) Summaries for Softmax & Linear\n",
        "plot_accuracy_vs_runtime(\n",
        "    runtimes_clean=runtimes_softmax,\n",
        "    accuracies_clean=accuracies_softmax,\n",
        "    title=\"Softmax: Accuracy vs. Runtime\"\n",
        ")\n",
        "plot_accuracy_vs_runtime(\n",
        "    runtimes_clean=runtimes_linear,\n",
        "    accuracies_clean=accuracies_linear,\n",
        "    title=\"Linear: Accuracy vs. Runtime\"\n",
        ")\n",
        "plot_accuracy_vs_runtime(\n",
        "    runtimes_clean=runtimes_softmax,\n",
        "    accuracies_clean=accuracies_softmax,\n",
        "    runtimes_pocket=runtimes_linear,\n",
        "    accuracies_pocket=accuracies_linear,\n",
        "    title=\"Softmax vs. Linear: Accuracy vs. Runtime\"\n",
        ")\n",
        "plot_performance_summary_extended_by_runtime(\n",
        "    runtimes_clean=runtimes_softmax,\n",
        "    accuracies_clean=accuracies_softmax,\n",
        "    sensitivities_clean=sensitivities_soft,\n",
        "    selectivities_clean=selectivities_soft,\n",
        "    runtimes_pocket=runtimes_linear,\n",
        "    accuracies_pocket=accuracies_linear,\n",
        "    sensitivities_pocket=sensitivities_lin,\n",
        "    selectivities_pocket=selectivities_lin,\n",
        "    title=\"Softmax vs. Linear: TPR/TNR vs. Runtime\"\n",
        ")\n",
        "\n",
        "# 5D) 4-Model Comparison\n",
        "plot_performance_summary_4models_by_runtime(\n",
        "    runtimes_clean, accuracies_clean, sensitivities_clean, selectivities_clean,\n",
        "    runtimes_pocket, accuracies_pocket, sensitivities_pocket, selectivities_pocket,\n",
        "    runtimes_softmax, accuracies_softmax, sensitivities_soft, selectivities_soft,\n",
        "    runtimes_linear, accuracies_linear, sensitivities_lin, selectivities_lin,\n",
        "    title=\"Performance vs. Runtime (4-Model Comparison)\"\n",
        ")\n",
        "\n",
        "plot_accuracy_vs_runtime_4models(\n",
        "    rt_clean=runtimes_clean,\n",
        "    acc_clean=accuracies_clean,\n",
        "    rt_pocket=runtimes_pocket,\n",
        "    acc_pocket=accuracies_pocket,\n",
        "    rt_softmax=runtimes_softmax,\n",
        "    acc_softmax=accuracies_softmax,\n",
        "    rt_linear=runtimes_linear,\n",
        "    acc_linear=accuracies_linear,\n",
        "    title=\"Accuracy vs. Runtime (4 Models)\"\n",
        ")\n",
        "\n",
        "logger.info(\"=== All Visualizations Complete ===\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
<<<<<<< HEAD
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VepUzPkWrANq"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Hech6_lrANq"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# EVALUATION CELL (with pandas DataFrame)\n",
    "##################################################\n",
    "\n",
    "\n",
    "# 1) Evaluate Perceptrons: Clean & Pocket\n",
    "accuracies_clean, accuracies_pocket = [], []\n",
    "runtimes_clean,   runtimes_pocket   = [], []\n",
    "sensitivities_clean, sensitivities_pocket = [], []\n",
    "selectivities_clean, selectivities_pocket = [], []\n",
    "\n",
    "conf_clean, conf_pocket = [], []\n",
    "meta_clean, meta_pocket = [], []\n",
    "\n",
    "for max_iter in tqdm(perceptron_max_iter_values, desc=\"Evaluate Clean & Pocket\"):\n",
    "    # === Evaluate Clean PLA ===\n",
    "    c_model = trained_models_clean[max_iter]\n",
    "    cm_c, acc_c, s_c, sp_c, rt_c, ex_c = evaluate_model(\n",
    "        c_model, X_test, y_test, classes=range(10), model_name=\"Clean PLA\"\n",
    "    )\n",
    "    accuracies_clean.append(acc_c)\n",
    "    runtimes_clean.append(rt_c)\n",
    "    sensitivities_clean.append(np.mean(s_c))\n",
    "    selectivities_clean.append(np.mean(sp_c))\n",
    "    conf_clean.append(cm_c)\n",
    "\n",
    "    cdict = {\n",
    "        \"max_iter\": max_iter,\n",
    "        \"accuracy\": acc_c,\n",
    "        \"runtime\": rt_c,\n",
    "        \"avg_sensitivity\": np.mean(s_c),\n",
    "        \"avg_selectivity\": np.mean(sp_c),\n",
    "        \"method\": \"Clean PLA\"\n",
    "    }\n",
    "    cdict.update(ex_c)\n",
    "    meta_clean.append(cdict)\n",
    "\n",
    "    # === Evaluate Pocket PLA ===\n",
    "    p_model = trained_models_pocket[max_iter]\n",
    "    cm_p, acc_p, s_p, sp_p, rt_p, ex_p = evaluate_model(\n",
    "        p_model, X_test, y_test, classes=range(10), model_name=\"Pocket PLA\"\n",
    "    )\n",
    "    accuracies_pocket.append(acc_p)\n",
    "    runtimes_pocket.append(rt_p)\n",
    "    sensitivities_pocket.append(np.mean(s_p))\n",
    "    selectivities_pocket.append(np.mean(sp_p))\n",
    "    conf_pocket.append(cm_p)\n",
    "\n",
    "    pdict = {\n",
    "        \"max_iter\": max_iter,\n",
    "        \"accuracy\": acc_p,\n",
    "        \"runtime\": rt_p,\n",
    "        \"avg_sensitivity\": np.mean(s_p),\n",
    "        \"avg_selectivity\": np.mean(sp_p),\n",
    "        \"method\": \"Pocket PLA\"\n",
    "    }\n",
    "    pdict.update(ex_p)\n",
    "    meta_pocket.append(pdict)\n",
    "\n",
    "# Aggregated iteration-level training curves for Perceptrons\n",
    "clean_train_curve = aggregate_iteration_losses(\n",
    "    [trained_models_clean[m] for m in perceptron_max_iter_values]\n",
    ")\n",
    "pocket_train_curve = aggregate_iteration_losses(\n",
    "    [trained_models_pocket[m] for m in perceptron_max_iter_values]\n",
    ")\n",
    "\n",
    "# 2) Evaluate Regression Models: Softmax & Linear\n",
    "accuracies_softmax = []\n",
    "runtimes_softmax   = []\n",
    "sensitivities_soft = []\n",
    "selectivities_soft = []\n",
    "conf_soft          = []\n",
    "meta_soft          = []\n",
    "\n",
    "accuracies_linear = []\n",
    "runtimes_linear   = []\n",
    "sensitivities_lin = []\n",
    "selectivities_lin = []\n",
    "conf_linear       = []\n",
    "meta_linear       = []\n",
    "\n",
    "for cfg in tqdm(regression_run_configs, desc=\"Evaluate Regressions\"):\n",
    "    lr_val = cfg[\"learning_rate\"]\n",
    "    max_iter_val = cfg[\"max_iter\"]\n",
    "    label = cfg[\"label\"]\n",
    "\n",
    "    # === Evaluate Softmax ===\n",
    "    s_model = trained_models_softmax[(lr_val, max_iter_val)]\n",
    "    cm_s, a_s, se_s, sp_s, r_s, ex_s = evaluate_model(\n",
    "        s_model, X_test, y_test, classes=range(10),\n",
    "        model_name=f\"Softmax ({label})\"\n",
    "    )\n",
    "    accuracies_softmax.append(a_s)\n",
    "    runtimes_softmax.append(r_s)\n",
    "    sensitivities_soft.append(np.mean(se_s))\n",
    "    selectivities_soft.append(np.mean(sp_s))\n",
    "    conf_soft.append(cm_s)\n",
    "\n",
    "    ms = {\n",
    "        \"label\": label,\n",
    "        \"learning_rate\": lr_val,\n",
    "        \"max_iter\": max_iter_val,\n",
    "        \"accuracy\": a_s,\n",
    "        \"runtime\": r_s,\n",
    "        \"avg_sensitivity\": np.mean(se_s),\n",
    "        \"avg_selectivity\": np.mean(sp_s),\n",
    "        \"method\": \"Softmax\"\n",
    "    }\n",
    "    ms.update(ex_s)\n",
    "    meta_soft.append(ms)\n",
    "\n",
    "    # === Evaluate Linear ===\n",
    "    lin_model = trained_models_linear[(lr_val, max_iter_val)]\n",
    "    cm_l, a_l, se_l, sp_l, r_l, ex_l = evaluate_model(\n",
    "        lin_model, X_test, y_test, classes=range(10),\n",
    "        model_name=f\"Linear ({label})\"\n",
    "    )\n",
    "    accuracies_linear.append(a_l)\n",
    "    runtimes_linear.append(r_l)\n",
    "    sensitivities_lin.append(np.mean(se_l))\n",
    "    selectivities_lin.append(np.mean(sp_l))\n",
    "    conf_linear.append(cm_l)\n",
    "\n",
    "    ml = {\n",
    "        \"label\": label,\n",
    "        \"learning_rate\": lr_val,\n",
    "        \"max_iter\": max_iter_val,\n",
    "        \"accuracy\": a_l,\n",
    "        \"runtime\": r_l,\n",
    "        \"avg_sensitivity\": np.mean(se_l),\n",
    "        \"avg_selectivity\": np.mean(sp_l),\n",
    "        \"method\": \"Linear Regression\"\n",
    "    }\n",
    "    ml.update(ex_l)\n",
    "    meta_linear.append(ml)\n",
    "\n",
    "\n",
    "logger.info(\"Evaluation complete for Perceptrons & Regressions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwCAybO5owmg"
   },
   "source": [
    "# Visualize (Generate Plots, Confusion Matricies, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC4vaIjVowmg"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# 1) CREATE A SINGLE PANDAS DATAFRAME FOR ALL RESULTS\n",
    "##################################################\n",
    "all_rows = []\n",
    "\n",
    "# (A) Clean PLA\n",
    "for i, max_iter in tqdm(\n",
    "    enumerate(perceptron_max_iter_values),\n",
    "    desc=\"Collecting Clean PLA\",\n",
    "    total=len(perceptron_max_iter_values)\n",
    "):\n",
    "    all_rows.append({\n",
    "        'model': 'Clean PLA',\n",
    "        'max_iter': max_iter,\n",
    "        'runtime': runtimes_clean[i],\n",
    "        'accuracy': accuracies_clean[i],\n",
    "        'sensitivity': sensitivities_clean[i],\n",
    "        'selectivity': selectivities_clean[i]\n",
    "    })\n",
    "\n",
    "# (B) Pocket PLA\n",
    "for i, max_iter in tqdm(\n",
    "    enumerate(perceptron_max_iter_values),\n",
    "    desc=\"Collecting Pocket PLA\",\n",
    "    total=len(perceptron_max_iter_values)\n",
    "):\n",
    "    all_rows.append({\n",
    "        'model': 'Pocket PLA',\n",
    "        'max_iter': max_iter,\n",
    "        'runtime': runtimes_pocket[i],\n",
    "        'accuracy': accuracies_pocket[i],\n",
    "        'sensitivity': sensitivities_pocket[i],\n",
    "        'selectivity': selectivities_pocket[i]\n",
    "    })\n",
    "\n",
    "# (C) Softmax\n",
    "for i, row_meta in tqdm(\n",
    "    enumerate(meta_soft),\n",
    "    desc=\"Collecting Softmax\",\n",
    "    total=len(meta_soft)\n",
    "):\n",
    "    all_rows.append({\n",
    "        'model': 'Softmax',\n",
    "        'max_iter': row_meta['max_iter'],\n",
    "        'runtime': runtimes_softmax[i],\n",
    "        'accuracy': accuracies_softmax[i],\n",
    "        'sensitivity': sensitivities_soft[i],\n",
    "        'selectivity': selectivities_soft[i]\n",
    "    })\n",
    "\n",
    "# (D) Linear\n",
    "for i, row_meta in tqdm(\n",
    "    enumerate(meta_linear),\n",
    "    desc=\"Collecting Linear\",\n",
    "    total=len(meta_linear)\n",
    "):\n",
    "    all_rows.append({\n",
    "        'model': 'Linear',\n",
    "        'max_iter': row_meta['max_iter'],\n",
    "        'runtime': runtimes_linear[i],\n",
    "        'accuracy': accuracies_linear[i],\n",
    "        'sensitivity': sensitivities_lin[i],\n",
    "        'selectivity': selectivities_lin[i]\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(all_rows)\n",
    "logger.info(\"Combined Results DataFrame:\\n%s\", df_results)\n",
    "display(df_results.head(20))\n",
    "\n",
    "############################################################################\n",
    "# 2) CONFUSION MATRICES FOR ALL MODELS (GROUPED BY PLOT TYPE)\n",
    "############################################################################\n",
    "\n",
    "logger.info(\"=== Plotting ALL Confusion Matrices ===\")\n",
    "\n",
    "# 2A) Perceptron: Clean\n",
    "for idx, meta in tqdm(enumerate(meta_clean), total=len(meta_clean), desc=\"Confusions: Clean PLA\"):\n",
    "    title = f\"Clean PLA (max_iter={meta['max_iter']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
    "    plot_confusion_matrix_annotated(\n",
    "        conf_clean[idx],\n",
    "        classes=range(10),\n",
    "        title=title,\n",
    "        method=meta[\"method\"],\n",
    "        max_iter=meta[\"max_iter\"]\n",
    "    )\n",
    "\n",
    "# 2B) Perceptron: Pocket\n",
    "for idx, meta in tqdm(enumerate(meta_pocket), total=len(meta_pocket), desc=\"Confusions: Pocket PLA\"):\n",
    "    title = f\"Pocket PLA (max_iter={meta['max_iter']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
    "    plot_confusion_matrix_annotated(\n",
    "        conf_pocket[idx],\n",
    "        classes=range(10),\n",
    "        title=title,\n",
    "        method=meta[\"method\"],\n",
    "        max_iter=meta[\"max_iter\"]\n",
    "    )\n",
    "\n",
    "# 2C) Softmax\n",
    "for idx, meta in tqdm(enumerate(meta_soft), total=len(meta_soft), desc=\"Confusions: Softmax\"):\n",
    "    title = f\"Softmax ({meta['label']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
    "    plot_confusion_matrix_annotated(\n",
    "        conf_soft[idx],\n",
    "        classes=range(10),\n",
    "        title=title,\n",
    "        method=meta[\"method\"],\n",
    "        max_iter=meta[\"max_iter\"]\n",
    "    )\n",
    "\n",
    "# 2D) Linear\n",
    "for idx, meta in tqdm(enumerate(meta_linear), total=len(meta_linear), desc=\"Confusions: Linear\"):\n",
    "    title = f\"Linear ({meta['label']}, Acc={meta['accuracy']*100:.2f}%)\"\n",
    "    plot_confusion_matrix_annotated(\n",
    "        conf_linear[idx],\n",
    "        classes=range(10),\n",
    "        title=title,\n",
    "        method=meta[\"method\"],\n",
    "        max_iter=meta[\"max_iter\"]\n",
    "    )\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# 3) ITERATION-LEVEL PLOTS (ALL MODELS)\n",
    "############################################################################\n",
    "\n",
    "logger.info(\"=== Iteration-Level Visualization (All Models) ===\")\n",
    "\n",
    "# 3A) Perceptron: Clean & Pocket\n",
    "for max_iter, c_model in trained_models_clean.items():\n",
    "    df_iter = c_model.get_iteration_df()\n",
    "    if not df_iter.empty and \"train_error\" in df_iter.columns:\n",
    "        title = f\"Clean PLA max_iter={max_iter}: Train Error vs. Iteration\"\n",
    "        df_iter.plot(x=\"iteration\", y=\"train_error\", marker='o', figsize=(8,5), title=title)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "for max_iter, p_model in trained_models_pocket.items():\n",
    "    df_iter = p_model.get_iteration_df()\n",
    "    if not df_iter.empty and \"train_error\" in df_iter.columns:\n",
    "        title = f\"Pocket PLA max_iter={max_iter}: Train Error vs. Iteration\"\n",
    "        df_iter.plot(x=\"iteration\", y=\"train_error\", marker='o', figsize=(8,5), title=title)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "# 3B) Softmax\n",
    "for (lr_val, max_iter_val), s_model in trained_models_softmax.items():\n",
    "    df_iter = s_model.get_iteration_df()  # Must be implemented in your SoftmaxRegression\n",
    "    if not df_iter.empty:\n",
    "        title = f\"Softmax LR={lr_val}, max_iter={max_iter_val}: Train Loss vs. Iteration\"\n",
    "        df_iter.plot(x=\"iteration\", y=\"train_loss\", marker='o', figsize=(8,5), title=title)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "        if \"test_loss\" in df_iter.columns:\n",
    "            title = f\"Softmax LR={lr_val}, max_iter={max_iter_val}: Train & Test Loss\"\n",
    "            df_iter.plot(x=\"iteration\", y=[\"train_loss\",\"test_loss\"], marker='o', figsize=(8,5), title=title)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.show()\n",
    "\n",
    "        if \"avg_adaptive_lr\" in df_iter.columns:\n",
    "            title = f\"Softmax LR={lr_val}, max_iter={max_iter_val}: Avg Adaptive LR vs. Iteration\"\n",
    "            df_iter.plot(x=\"iteration\", y=\"avg_adaptive_lr\", marker='x', figsize=(8,5), title=title)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.show()\n",
    "\n",
    "# 3C) Linear\n",
    "for (lr_val, max_iter_val), lin_model in trained_models_linear.items():\n",
    "    df_iter = lin_model.get_iteration_df()  # Must be implemented in your LinearRegression\n",
    "    if not df_iter.empty:\n",
    "        title = f\"Linear LR={lr_val}, max_iter={max_iter_val}: Train Loss vs. Iteration\"\n",
    "        df_iter.plot(x=\"iteration\", y=\"train_loss\", marker='o', figsize=(8,5), title=title)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "        if \"test_loss\" in df_iter.columns:\n",
    "            title = f\"Linear LR={lr_val}, max_iter={max_iter_val}: Train & Test Loss\"\n",
    "            df_iter.plot(x=\"iteration\", y=[\"train_loss\",\"test_loss\"], marker='o', figsize=(8,5), title=title)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.show()\n",
    "\n",
    "        if \"avg_adaptive_lr\" in df_iter.columns:\n",
    "            title = f\"Linear LR={lr_val}, max_iter={max_iter_val}: Avg Adaptive LR vs. Iteration\"\n",
    "            df_iter.plot(x=\"iteration\", y=\"avg_adaptive_lr\", marker='x', figsize=(8,5), title=title)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# 4) PANDAS + SEABORN PLOTS\n",
    "############################################################################\n",
    "\n",
    "logger.info(\"=== Pandas + Seaborn Plots ===\")\n",
    "\n",
    "# 4A) LINE PLOT: Accuracy vs. max_iter (Perceptrons Only)\n",
    "df_perc = df_results[df_results['model'].isin(['Clean PLA','Pocket PLA'])].copy()\n",
    "df_perc.sort_values(['model','max_iter'], inplace=True)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.lineplot(\n",
    "    data=df_perc,\n",
    "    x='max_iter', y='accuracy',\n",
    "    hue='model', marker='o'\n",
    ")\n",
    "plt.title(\"Perceptrons: Accuracy vs. max_iter (Pandas/Seaborn)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 4B) BAR CHART: Average Accuracy by Model\n",
    "df_mean = df_results.groupby('model', as_index=False)['accuracy'].mean()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(data=df_mean, x='model', y='accuracy')\n",
    "plt.title(\"Average Accuracy by Model (Pandas/Seaborn)\")\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 4C) SCATTER PLOT: Accuracy vs. Runtime, colored by model\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(\n",
    "    data=df_results,\n",
    "    x='runtime', y='accuracy',\n",
    "    hue='model', style='model',\n",
    "    s=100\n",
    ")\n",
    "plt.title(\"Accuracy vs. Runtime (All Models) (Pandas/Seaborn)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# 5) CUSTOM SUMMARY PLOTS (AGGREGATED CURVES, ETC.)\n",
    "############################################################################\n",
    "\n",
    "logger.info(\"=== Custom Summaries (Aggregated Curves, etc.) ===\")\n",
    "\n",
    "# 5A) Aggregated Perceptron Curves\n",
    "plot_train_curves_three_models(\n",
    "    clean_train_curve=clean_train_curve,\n",
    "    pocket_train_curve=pocket_train_curve,\n",
    "    softmax_train_curve=None,  # no Softmax aggregator\n",
    "    title=\"Aggregated Perceptron Train Curves (Clean vs. Pocket)\",\n",
    "    max_iter=perceptron_max_iter_values[-1]\n",
    ")\n",
    "\n",
    "# 5B) Summaries for Perceptron\n",
    "plot_accuracy_vs_max_iter(\n",
    "    max_iter_values=perceptron_max_iter_values,\n",
    "    accuracies_clean=accuracies_clean,\n",
    "    accuracies_pocket=accuracies_pocket,\n",
    "    accuracies_softmax=None\n",
    ")\n",
    "\n",
    "plot_runtime_vs_max_iter(\n",
    "    max_iter_values=perceptron_max_iter_values,\n",
    "    runtimes_clean=runtimes_clean,\n",
    "    runtimes_pocket=runtimes_pocket,\n",
    "    runtimes_softmax=None\n",
    ")\n",
    "\n",
    "plot_accuracy_vs_runtime(\n",
    "    runtimes_clean=runtimes_clean,\n",
    "    accuracies_clean=accuracies_clean,\n",
    "    runtimes_pocket=runtimes_pocket,\n",
    "    accuracies_pocket=accuracies_pocket,\n",
    "    title=\"Perceptrons: Accuracy vs. Runtime\"\n",
    ")\n",
    "\n",
    "plot_performance_summary_extended_by_runtime(\n",
    "    runtimes_clean=runtimes_clean,\n",
    "    accuracies_clean=accuracies_clean,\n",
    "    sensitivities_clean=sensitivities_clean,\n",
    "    selectivities_clean=selectivities_clean,\n",
    "    runtimes_pocket=runtimes_pocket,\n",
    "    accuracies_pocket=accuracies_pocket,\n",
    "    sensitivities_pocket=sensitivities_pocket,\n",
    "    selectivities_pocket=selectivities_pocket,\n",
    "    title=\"Perceptrons: Performance vs. Runtime\"\n",
    ")\n",
    "\n",
    "# 5C) Summaries for Softmax & Linear\n",
    "plot_accuracy_vs_runtime(\n",
    "    runtimes_clean=runtimes_softmax,\n",
    "    accuracies_clean=accuracies_softmax,\n",
    "    title=\"Softmax: Accuracy vs. Runtime\"\n",
    ")\n",
    "plot_accuracy_vs_runtime(\n",
    "    runtimes_clean=runtimes_linear,\n",
    "    accuracies_clean=accuracies_linear,\n",
    "    title=\"Linear: Accuracy vs. Runtime\"\n",
    ")\n",
    "plot_accuracy_vs_runtime(\n",
    "    runtimes_clean=runtimes_softmax,\n",
    "    accuracies_clean=accuracies_softmax,\n",
    "    runtimes_pocket=runtimes_linear,\n",
    "    accuracies_pocket=accuracies_linear,\n",
    "    title=\"Softmax vs. Linear: Accuracy vs. Runtime\"\n",
    ")\n",
    "plot_performance_summary_extended_by_runtime(\n",
    "    runtimes_clean=runtimes_softmax,\n",
    "    accuracies_clean=accuracies_softmax,\n",
    "    sensitivities_clean=sensitivities_soft,\n",
    "    selectivities_clean=selectivities_soft,\n",
    "    runtimes_pocket=runtimes_linear,\n",
    "    accuracies_pocket=accuracies_linear,\n",
    "    sensitivities_pocket=sensitivities_lin,\n",
    "    selectivities_pocket=selectivities_lin,\n",
    "    title=\"Softmax vs. Linear: TPR/TNR vs. Runtime\"\n",
    ")\n",
    "\n",
    "# 5D) 4-Model Comparison\n",
    "plot_performance_summary_4models_by_runtime(\n",
    "    runtimes_clean, accuracies_clean, sensitivities_clean, selectivities_clean,\n",
    "    runtimes_pocket, accuracies_pocket, sensitivities_pocket, selectivities_pocket,\n",
    "    runtimes_softmax, accuracies_softmax, sensitivities_soft, selectivities_soft,\n",
    "    runtimes_linear, accuracies_linear, sensitivities_lin, selectivities_lin,\n",
    "    title=\"Performance vs. Runtime (4-Model Comparison)\"\n",
    ")\n",
    "\n",
    "plot_accuracy_vs_runtime_4models(\n",
    "    rt_clean=runtimes_clean,\n",
    "    acc_clean=accuracies_clean,\n",
    "    rt_pocket=runtimes_pocket,\n",
    "    acc_pocket=accuracies_pocket,\n",
    "    rt_softmax=runtimes_softmax,\n",
    "    acc_softmax=accuracies_softmax,\n",
    "    rt_linear=runtimes_linear,\n",
    "    acc_linear=accuracies_linear,\n",
    "    title=\"Accuracy vs. Runtime (4 Models)\"\n",
    ")\n",
    "\n",
    "logger.info(\"=== All Visualizations Complete ===\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "cell_execution_strategy": "setup",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
=======
  "nbformat": 4,
  "nbformat_minor": 0
}
>>>>>>> 2608f0c3b13bc9dce506ddd8f0511a461767d1c6
