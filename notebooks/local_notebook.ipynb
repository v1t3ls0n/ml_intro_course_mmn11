{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ztlf-kRcUjIz"
   },
   "source": [
    "# Maman 11 By Guy Vitelson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXiZOQmO5Tak"
   },
   "source": [
    "##**If you run this within Google Collab, Dont Worry!**\n",
    "all the missing python files/directories/modules will be automatically feteched from my github repository\n",
    "\n",
    "**My GitHub Profile** : https://github.com/v1t3ls0n\n",
    "\n",
    "**The Repository:** https://github.com/v1t3ls0n/ml_intro_course_mmn11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKs0r5ROHxuY"
   },
   "source": [
    "# Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWMyo4jnR-mx"
   },
   "source": [
    "## MNIST Digit Classification Using Perceptron Learning Algorithm (PLA)\n",
    "\n",
    "**Objective:**  \n",
    "This notebook compares the performance of two variants of the Perceptron Learning Algorithm (PLA) on the MNIST digit classification task:\n",
    "- **Clean PLA:** Standard perceptron without enhancements.\n",
    "- **Pocket PLA:** Enhanced perceptron that stores the best-performing weights during training (using the Pocket algorithm).\n",
    "\n",
    "**Dataset:**  \n",
    "- MNIST dataset consisting of 60,000 training samples and 10,000 test samples.\n",
    "- The images are normalized to the range [0, 1] and a bias term is added, resulting in input samples with 785 features.\n",
    "\n",
    "**Evaluation Metrics:**  \n",
    "- **Confusion Matrices:** Provides a detailed view of how well each digit is classified.\n",
    "- **Overall Accuracy (ACC):** Defined as \\(\\text{ACC} = \\frac{TP + TN}{TP + TN + FP + FN}\\).\n",
    "- **Sensitivity (True Positive Rate, TPR):** For each digit, calculated as \\(\\text{TPR} = \\frac{TP}{TP + FN}\\), showing the model’s ability to correctly identify the digit.\n",
    "- **Selectivity (Specificity, TNR):** For each digit, calculated as \\(\\text{TNR} = \\frac{TN}{TN + FP}\\), showing the model’s ability to correctly identify negatives.\n",
    "- **Training and Testing Error Curves:** Visualized as a function of iteration for detailed analysis of learning dynamics.\n",
    "- **Runtime:** The time taken to train the models.\n",
    "\n",
    "**Goals:**  \n",
    "- Evaluate and compare the model accuracy and robustness between Clean PLA and Pocket PLA.\n",
    "- Analyze and visualize the performance through confusion matrices, error curves, and summary plots (accuracy, sensitivity, selectivity, and runtime vs. the number of iterations).\n",
    "- Provide a comprehensive discussion on how training iterations affect the decision boundaries and the overall performance, particularly in the one-vs-all classification setup.\n",
    "\n",
    "This notebook integrates detailed quantitative evaluation with comprehensive visualizations to thoroughly analyze the multi-class Perceptron performance on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keDSGERzwvrB"
   },
   "source": [
    "# Choose Run Parameters **(Significant Effect On Model's Runtime!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAz6LnbGxLR1"
   },
   "source": [
    "## Perceptron Models\n",
    "I implemented two multi-class perceptron models, one that uses the pocket algorithm and one that doesn't use it (\"clean\" version). Choose the max iteration parameter (1 or more) you want for these models. Itwof you choose more than one value for this run parameter and comprehensive analysis and comparison\n",
    "of their performance differences will be provided visually and will give you an insight into how the changes in that run parameter affect their performances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D1zODCVjxz3y"
   },
   "outputs": [],
   "source": [
    "max_iter_values = [1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqLIUat1dEr2"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmauUwgLR-mx"
   },
   "source": [
    "## External Code Imports (pip packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xUkaAHQFR-mx"
   },
   "outputs": [],
   "source": [
    "%%capture run_output\n",
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlMUAQraR-my"
   },
   "source": [
    "## Fetch Missing Files For Google Colab Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msKnbktXR-my"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     sys.path.insert(\u001b[32m0\u001b[39m, core_path)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Data Preprocessing:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmnist_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_mnist\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_preprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_data\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Models (Multi-Class Perceptron, Softmax Regression):\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "%%capture run_output\n",
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "if sys.platform != 'win32': # check if we are running on google collab\n",
    "  repo_url = \"https://github.com/v1t3ls0n/ml_intro_course_mmn11\"\n",
    "  repo_name = \"ml_intro_course_mmn11\"\n",
    "  from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "  # Clone the repository if it doesn't exist\n",
    "  if not os.path.exists(repo_name):\n",
    "    os.system(f\"git clone {repo_url}\")\n",
    "\n",
    "  # Construct the path to the repository directory\n",
    "  repo_path = os.path.join(os.getcwd(), repo_name)\n",
    "\n",
    "  # Add the repository directory to the Python path\n",
    "  if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "\n",
    "  # --- Extract 'core' and 'notebooks' directories ---\n",
    "  def extract_directories(source_dir, destination_dir, dir_names):\n",
    "      for dir_name in dir_names:\n",
    "          source_path = os.path.join(source_dir, dir_name)\n",
    "          destination_path = os.path.join(destination_dir, dir_name)\n",
    "          if os.path.exists(source_path):\n",
    "              shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
    "\n",
    "  destination_path = \".\"\n",
    "  # Extract the directories\n",
    "  extract_directories(repo_path, destination_path, [\"core\"])\n",
    "  project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "  sys.path.insert(0, project_root)\n",
    "  if os.path.exists(\"ml_intro_course_mmn11\"):\n",
    "    shutil.rmtree(\"ml_intro_course_mmn11\")\n",
    "else:\n",
    "  from tqdm import tqdm # type: ignore\n",
    "\n",
    "# Ensure the 'core' directory is in the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "core_path = os.path.join(project_root, 'core')\n",
    "if core_path not in sys.path:\n",
    "    sys.path.insert(0, core_path)\n",
    "\n",
    "# Data Preprocessing:\n",
    "from core.data.mnist_loader import load_mnist\n",
    "from core.data.data_preprocessing import preprocess_data\n",
    "\n",
    "# Models (Multi-Class Perceptron, Softmax Regression):\n",
    "from core.models.perceptron.multi_class_perceptron import MultiClassPerceptron\n",
    "\n",
    "# Performance Evaluation, Analysis and Plotting:\n",
    "from core.analysis.evaluation_functions import evaluate_model,aggregate_iteration_losses\n",
    "from core.analysis.plotting import plot_error_curves, plot_accuracy_vs_max_iter,plot_runtime_vs_max_iter,plot_performance_summary,plot_performance_summary_extended,plot_confusion_matrix_annotated\n",
    "\n",
    "logger = logging.getLogger(\"MyGlobalLogger\") # configured in core/logger/coifg.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYrRE0dcR-my"
   },
   "source": [
    "## Internal Code Imports (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTaL_MsqeE00"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing:\n",
    "from core.data.mnist_loader import load_mnist\n",
    "from core.data.data_preprocessing import preprocess_data\n",
    "\n",
    "# Models (Multi-Class Perceptron, Softmax Regression):\n",
    "from core.models.perceptron.multi_class_perceptron import MultiClassPerceptron\n",
    "\n",
    "# Performance Evaluation, Analysis and Plotting:\n",
    "from core.analysis.evaluation_functions import evaluate_model,aggregate_iteration_losses\n",
    "from core.analysis.plotting import plot_error_curves, plot_accuracy_vs_max_iter,plot_runtime_vs_max_iter,plot_performance_summary,plot_performance_summary_extended,plot_confusion_matrix_annotated\n",
    "\n",
    "logger = logging.getLogger(\"MyGlobalLogger\") # configured in core/logger/coifg.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e73BoKY7cmJU"
   },
   "source": [
    "# Load and Preprocess the MNIST Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osGLi3Hic5qW",
    "outputId": "1f0be7c8-fa66-456b-d779-879dcd56edbc"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We'll load the MNIST dataset using our custom loader (`mnist_loader`) and then apply preprocessing (`data_preprocessing`).\n",
    "The preprocessing step normalizes each image to the range [0, 1] and adds a bias term, resulting in input samples with 785 features.\n",
    "This setup ensures that the training set contains 60,000 samples and the test set 10,000 samples, preparing the data for the subsequent classification tasks.\n",
    "'''\n",
    "\n",
    "# New section\n",
    "# Load raw MNIST data (X: images, y: labels)\n",
    "X_raw, y_raw = load_mnist()\n",
    "\n",
    "\n",
    "logger.info(\"Raw MNIST data shapes: X_raw: %s, y_raw: %s\", X_raw.shape, y_raw.shape)\n",
    "\n",
    "# Preprocess (normalize & add bias = True)\n",
    "X = preprocess_data(X_raw, add_bias=True, normalize=True)\n",
    "logger.info(\"Preprocessed shape: %s\", X.shape)\n",
    "\n",
    "# Split into train/test manually or with 60k/10k as the task suggests\n",
    "X_train, y_train = X[:60000], y_raw[:60000]\n",
    "X_test,  y_test  = X[60000:], y_raw[60000:]\n",
    "\n",
    "logger.info(\"Train set: X_train: %s, y_train: %s\", X_train.shape, y_train.shape)\n",
    "logger.info(\"Test set: X_test: %s, y_test: %s\", X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-O4hrMBCejtr"
   },
   "source": [
    "# Train Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3cb9c62b7083473b811f5c890eefa556",
      "17215092221b438f815e82a05f47aa85",
      "1727d82232ef438fa39b9d5dac34a4f4",
      "fb0ab62441f5416c80e0131de063993a",
      "fdadcec6eca64a019404b913936946c4",
      "ade574cb8fb44dfaad4f39b7e7b70c8f",
      "353d62f5dabb454ab39c21083c12c9b9",
      "d8c4a74cd658445394dcb734943cab7d",
      "d5bec332a67943e8bc8a5e0904b9b009",
      "ba67bf974f954d9fa213a28248fdfc4a",
      "bbdaf2752206407aa83dd80b7054121d"
     ]
    },
    "id": "Sik1JDX6Hxub",
    "outputId": "1628ff5d-5ab8-4a71-a067-538c8eb6c1a9"
   },
   "outputs": [],
   "source": [
    "# Dictionaries to store trained models\n",
    "trained_models_clean = {}\n",
    "trained_models_pocket = {}\n",
    "\n",
    "# Lists to store accuracy, runtime, sensitivity, and selectivity results\n",
    "accuracies_clean = []\n",
    "accuracies_pocket = []\n",
    "runtimes_clean = []\n",
    "runtimes_pocket = []\n",
    "sensitivities_clean = []\n",
    "sensitivities_pocket = []\n",
    "selectivities_clean = []\n",
    "selectivities_pocket = []\n",
    "\n",
    "# Lists to store confusion matrices and metadata for later plotting\n",
    "conf_matrices_clean = []\n",
    "conf_matrices_pocket = []\n",
    "metadata_clean = []\n",
    "metadata_pocket = []\n",
    "\n",
    "# ========== Train Clean and Pocket PLA for different max_iter values ==========\n",
    "for max_iter in tqdm(max_iter_values, desc=\"Training Models\"):\n",
    "    logger.info(f\"=== Training PLA Clean Model (Without Using Pocket Algorithm) with max_iter={max_iter} ===\")\n",
    "    # Train Clean PLA\n",
    "    clean_perceptron = MultiClassPerceptron(num_classes=10, max_iter=max_iter, use_pocket=False)\n",
    "    clean_perceptron.fit(X_train, y_train)\n",
    "    trained_models_clean[max_iter] = clean_perceptron\n",
    "\n",
    "    logger.info(f\"Training complete for PLA Pocket Model With max_iter={max_iter}\")\n",
    "    # Train Pocket PLA\n",
    "    pocket_perceptron = MultiClassPerceptron(num_classes=10, max_iter=max_iter, use_pocket=True)\n",
    "    pocket_perceptron.fit(X_train, y_train)\n",
    "    trained_models_pocket[max_iter] = pocket_perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YObSvc0zowmg"
   },
   "source": [
    "# Evaluate Models and Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRO4N9Jnowmg"
   },
   "outputs": [],
   "source": [
    "# ========== Evaluate Models ==========\n",
    "for max_iter in tqdm(max_iter_values, desc=\"Evaluating Models\"):\n",
    "    logger.info(f\"=== Evaluating PLA Models (clean model, pocket model) With max_iter={max_iter} ===\")\n",
    "\n",
    "    # Retrieve trained models\n",
    "    clean_perceptron = trained_models_clean[max_iter]\n",
    "    pocket_perceptron = trained_models_pocket[max_iter]\n",
    "\n",
    "    # Evaluate Clean PLA; note the extra returned dictionary for future use.\n",
    "    cm_clean, acc_clean, sens_clean, spec_clean, runtime_clean, extra_clean = evaluate_model(\n",
    "        clean_perceptron, X_test, y_test, classes=list(range(10)), model_name=\"clean PLA\"\n",
    "    )\n",
    "    accuracies_clean.append(acc_clean)\n",
    "    sensitivities_clean.append(np.mean(sens_clean))   # Mean sensitivity for reporting\n",
    "    selectivities_clean.append(np.mean(spec_clean))     # Mean selectivity for reporting\n",
    "    runtimes_clean.append(runtime_clean)\n",
    "    # Store confusion matrix and merge extra info with basic metadata for later plotting\n",
    "    conf_matrices_clean.append(cm_clean)\n",
    "    meta_clean = {\n",
    "         \"max_iter\": max_iter,\n",
    "         \"accuracy\": acc_clean,\n",
    "         \"method\": \"clean PLA\"\n",
    "    }\n",
    "    meta_clean.update(extra_clean)\n",
    "    metadata_clean.append(meta_clean)\n",
    "\n",
    "    # Evaluate Pocket PLA; also retrieve extra info for future use.\n",
    "    cm_pocket, acc_pocket, sens_pocket, spec_pocket, runtime_pocket, extra_pocket = evaluate_model(\n",
    "        pocket_perceptron, X_test, y_test, classes=list(range(10)), model_name=\"pocket PLA\"\n",
    "    )\n",
    "    accuracies_pocket.append(acc_pocket)\n",
    "    sensitivities_pocket.append(np.mean(sens_pocket))   # Mean sensitivity for reporting\n",
    "    selectivities_pocket.append(np.mean(spec_pocket))     # Mean selectivity for reporting\n",
    "    runtimes_pocket.append(runtime_pocket)\n",
    "    # Store confusion matrix and merge extra info with basic metadata for later plotting\n",
    "    conf_matrices_pocket.append(cm_pocket)\n",
    "    meta_pocket = {\n",
    "         \"max_iter\": max_iter,\n",
    "         \"accuracy\": acc_pocket,\n",
    "         \"method\": \"pocket PLA\"\n",
    "    }\n",
    "    meta_pocket.update(extra_pocket)\n",
    "    metadata_pocket.append(meta_pocket)\n",
    "\n",
    "# Aggregate training curves across all `max_iter` runs\n",
    "clean_train_curve = aggregate_iteration_losses(list(trained_models_clean.values()))\n",
    "pocket_train_curve = aggregate_iteration_losses(list(trained_models_pocket.values()))\n",
    "\n",
    "# Print out a summary of the metrics:\n",
    "logger.info(\"Mean Sensitivity (TPR) for Clean PLA: %s\", sensitivities_clean)\n",
    "logger.info(\"Mean Sensitivity (TPR) for Pocket PLA: %s\", sensitivities_pocket)\n",
    "logger.info(\"Mean Selectivity (TNR) for Clean PLA: %s\", selectivities_clean)\n",
    "logger.info(\"Mean Selectivity (TNR) for Pocket PLA: %s\", selectivities_pocket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwCAybO5owmg"
   },
   "source": [
    "# Visualize (Generate Plots, Confusion Matricies, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC4vaIjVowmg"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ========== Plot Confusion Matrices ==========\n",
    "\n",
    "# Plot confusion matrices for the Clean PLA models\n",
    "for idx, meta in tqdm(enumerate(metadata_clean), total=len(metadata_clean), desc=\"Plotting Clean Confusion Matrices\"):\n",
    "    title = f\"Annotated Confusion Matrix - Clean PLA\\n(max_iter={meta['max_iter']}, Accuracy: {meta['accuracy']*100:.2f}%)\"\n",
    "    plot_confusion_matrix_annotated(\n",
    "        conf_matrices_clean[idx],\n",
    "        classes=list(range(10)),\n",
    "        title=title,\n",
    "        save_path=None,  # Optionally, specify a file path to save the figure\n",
    "        method=meta['method'],\n",
    "        max_iter=meta['max_iter']\n",
    "    )\n",
    "\n",
    "# Plot confusion matrices for the Pocket PLA models\n",
    "for idx, meta in tqdm(enumerate(metadata_pocket), total=len(metadata_pocket), desc=\"Plotting Pocket Confusion Matrices\"):\n",
    "    title = f\"Annotated Confusion Matrix - Pocket PLA\\n(max_iter={meta['max_iter']}, Accuracy: {meta['accuracy']*100:.2f}%)\"\n",
    "    plot_confusion_matrix_annotated(\n",
    "        conf_matrices_pocket[idx],\n",
    "        classes=list(range(10)),\n",
    "        title=title,\n",
    "        save_path=None,  # Optionally, specify a file path to save the figure\n",
    "        method=meta['method'],\n",
    "        max_iter=meta['max_iter']\n",
    "    )\n",
    "\n",
    "# ========== Plot Error Curves ==========\n",
    "plot_error_curves(\n",
    "    train_curve=clean_train_curve,\n",
    "    test_curve=pocket_train_curve,\n",
    "    title=\"Clean PLA vs. Pocket PLA (Avg. Train Error)\"\n",
    ")\n",
    "\n",
    "# ========== Summary Plots ==========\n",
    "# Plot accuracy vs. max_iter\n",
    "plot_accuracy_vs_max_iter(\n",
    "    max_iter_values,\n",
    "    accuracies_clean,\n",
    "    accuracies_pocket,\n",
    ")\n",
    "\n",
    "# Plot runtime vs. max_iter\n",
    "plot_runtime_vs_max_iter(\n",
    "    max_iter_values,\n",
    "    runtimes_clean,\n",
    "    runtimes_pocket,\n",
    ")\n",
    "\n",
    "# Plot comprehensive summary: Accuracy, Sensitivity (TPR), Selectivity (TNR), and Runtime vs. max_iter\n",
    "plot_performance_summary_extended(\n",
    "    max_iter_values,\n",
    "    accuracies_clean, accuracies_pocket,\n",
    "    sensitivities_clean, sensitivities_pocket,\n",
    "    selectivities_clean, selectivities_pocket,\n",
    "    runtimes_clean, runtimes_pocket,\n",
    ")\n",
    "\n",
    "# Generate performance summary plots\n",
    "# plot_performance_summary(max_iter_values, accuracies_clean, accuracies_pocket,\n",
    "#                          sensitivities_clean, sensitivities_pocket,\n",
    "#                          runtimes_clean, runtimes_pocket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mRmCfTiHxuc"
   },
   "source": [
    "# Final Results Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSf_XT9J3Km1"
   },
   "source": [
    "\n",
    "**Observations:**\n",
    "- **Pocket PLA** consistently outperforms Clean PLA in both accuracy and sensitivity (TPR) across all tested iteration counts.\n",
    "- Increasing `max_iter` improves performance, though gains tend to plateau beyond roughly 50–100 iterations.\n",
    "- **Runtime** increases nearly linearly with `max_iter` for both methods, highlighting a clear trade-off between higher accuracy and computational cost.\n",
    "- Perfect linear separation is not achieved—even at higher iteration counts, neither method reaches 100% accuracy, indicating that the dataset is not strictly linearly separable.\n",
    "\n",
    "**Trade-off Analysis:**\n",
    "- **Low Iterations (max_iter = 10–30):**  \n",
    "  Fast training with modest accuracy and TPR, suitable for rapid prototyping or time-sensitive applications.\n",
    "- **Medium Iterations (max_iter = 50–100):**  \n",
    "  Balanced performance and runtime, capturing most achievable gains without excessive overhead.\n",
    "- **High Iterations (max_iter > 100):**  \n",
    "  Marginal performance improvements with significant runtime increase; diminishing returns for practical applications.\n",
    "\n",
    "**Recommendations for Future Work:**\n",
    "- Experiment with alternative update rules (e.g., adaptive learning rates) to accelerate convergence.\n",
    "- Compare against more sophisticated models (e.g., Logistic Regression, SVMs, neural networks) for broader insights.\n",
    "- Evaluate model robustness under noisy or adversarial conditions.\n",
    "\n",
    "This comprehensive analysis—including confusion matrices, error curves, and summary plots—provides detailed insights into the performance of the multi-class Perceptron on MNIST and informs the optimal balance between training efficiency and classification performance.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17215092221b438f815e82a05f47aa85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade574cb8fb44dfaad4f39b7e7b70c8f",
      "placeholder": "​",
      "style": "IPY_MODEL_353d62f5dabb454ab39c21083c12c9b9",
      "value": "Training Models:  75%"
     }
    },
    "1727d82232ef438fa39b9d5dac34a4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8c4a74cd658445394dcb734943cab7d",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5bec332a67943e8bc8a5e0904b9b009",
      "value": 3
     }
    },
    "353d62f5dabb454ab39c21083c12c9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cb9c62b7083473b811f5c890eefa556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17215092221b438f815e82a05f47aa85",
       "IPY_MODEL_1727d82232ef438fa39b9d5dac34a4f4",
       "IPY_MODEL_fb0ab62441f5416c80e0131de063993a"
      ],
      "layout": "IPY_MODEL_fdadcec6eca64a019404b913936946c4"
     }
    },
    "ade574cb8fb44dfaad4f39b7e7b70c8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba67bf974f954d9fa213a28248fdfc4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbdaf2752206407aa83dd80b7054121d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5bec332a67943e8bc8a5e0904b9b009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d8c4a74cd658445394dcb734943cab7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb0ab62441f5416c80e0131de063993a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba67bf974f954d9fa213a28248fdfc4a",
      "placeholder": "​",
      "style": "IPY_MODEL_bbdaf2752206407aa83dd80b7054121d",
      "value": " 3/4 [06:09&lt;02:21, 141.05s/it]"
     }
    },
    "fdadcec6eca64a019404b913936946c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
