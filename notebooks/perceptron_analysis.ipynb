{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification Using Perceptron Learning Algorithm (PLA)\n",
    "\n",
    "**Objective**:  \n",
    "This notebook compares the performance of two variants of the Perceptron Learning Algorithm (PLA) on the MNIST digit classification task:\n",
    "- **Clean PLA**: Standard perceptron without enhancements.\n",
    "- **Pocket PLA**: Enhanced perceptron that stores the best-performing weights.\n",
    "\n",
    "**Dataset**:  \n",
    "- MNIST dataset (60,000 training samples and 10,000 test samples).\n",
    "- Images normalized to range [0, 1] and bias term added.\n",
    "\n",
    "**Evaluation Metrics**:  \n",
    "- Confusion matrices\n",
    "- Overall accuracy (ACC)\n",
    "- Sensitivity (True Positive Rate - TPR) for each digit class\n",
    "- Training and testing error curves for detailed iteration analysis\n",
    "\n",
    "**Goals**:  \n",
    "- Evaluate and compare model accuracy and robustness between Clean and Pocket PLA.\n",
    "- Visualize and analyze model performance in depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture run_output\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming 'notebooks/' is one folder below your project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.logger.config import logger\n",
    "from core.data.mnist_loader import load_mnist\n",
    "from core.data.data_preprocessing import preprocess_data\n",
    "from core.models.perceptron.multi_class_perceptron import MultiClassPerceptron\n",
    "from core.analysis.evaluation_functions import evaluate_model\n",
    "from core.analysis.plotting import plot_error_curves\n",
    "\n",
    "# Ensure results directories exist\n",
    "os.makedirs(\"results/perceptron_results/clean\", exist_ok=True)\n",
    "os.makedirs(\"results/perceptron_results/pocket\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess the MNIST Dataset\n",
    "\n",
    "We'll load the MNIST dataset using our custom loader (`mnist_loader`) and then apply preprocessing (`data_preprocessing`), which normalizes each image to [0,1] and adds a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data.mnist_loader import load_mnist\n",
    "from core.data.data_preprocessing import preprocess_data\n",
    "# Load raw MNIST data (X: images, y: labels)\n",
    "X_raw, y_raw = load_mnist()\n",
    "\n",
    "print(\"Raw MNIST data shapes:\")\n",
    "print(\"X_raw:\", X_raw.shape, \"y_raw:\", y_raw.shape)\n",
    "\n",
    "# Preprocess (normalize & add bias = True)\n",
    "X = preprocess_data(X_raw, add_bias=True, normalize=True)\n",
    "print(\"Preprocessed shape:\", X.shape)\n",
    "\n",
    "# Split into train/test manually or with 60k/10k as the task suggests\n",
    "X_train, y_train = X[:60000], y_raw[:60000]\n",
    "X_test,  y_test  = X[60000:], y_raw[60000:]\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set: \", X_test.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Clean vs Pocket Perceptron\n",
    "\n",
    "We instantiate our `MultiClassPerceptron` in **clean** (no-pocket) mode and **pocket** mode, train each one on the MNIST training set, and evaluate on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logger.config import logger\n",
    "from core.models.perceptron.multi_class_perceptron import MultiClassPerceptron\n",
    "\n",
    "# === Clean PLA ===\n",
    "logger.info(\"=== Training Clean PLA ===\")\n",
    "clean_perceptron = MultiClassPerceptron(\n",
    "    num_classes=10, \n",
    "    max_iter=1000, \n",
    "    use_pocket=False\n",
    ")\n",
    "clean_perceptron.fit(X_train, y_train)\n",
    "\n",
    "# === Pocket PLA ===\n",
    "logger.info(\"=== Training Pocket PLA ===\")\n",
    "pocket_perceptron = MultiClassPerceptron(\n",
    "    num_classes=10, \n",
    "    max_iter=1000, \n",
    "    use_pocket=True\n",
    ")\n",
    "pocket_perceptron.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Models and Plot Training Error Curves\n",
    "\n",
    "Here we:\n",
    "1. **Evaluate** both models using `evaluate_model` (confusion matrices, accuracy, sensitivity).\n",
    "2. **Analyze** confusion matrices more deeply (optional advanced metrics).\n",
    "3. **Plot** the training error curves immediately after the evaluation for an integrated view.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from core.logger.config import logger\n",
    "from core.analysis.evaluation_functions import evaluate_model\n",
    "from core.analysis.plotting import plot_error_curves\n",
    "\n",
    "classes = list(range(10))  # Digits 0..9\n",
    "plot_dir_clean = \"results/perceptron_results/clean\"\n",
    "plot_dir_pocket = \"results/perceptron_results/pocket\"\n",
    "\n",
    "# ========== Evaluate Clean PLA ==========\n",
    "logger.info(\"=== Evaluating Clean PLA ===\")\n",
    "cm_clean, acc_clean, sens_clean = evaluate_model(\n",
    "    model=clean_perceptron, \n",
    "    X=X_test, \n",
    "    y=y_test, \n",
    "    classes=classes, \n",
    "    plot_dir=plot_dir_clean\n",
    ")\n",
    "print(f\"[CLEAN] Accuracy: {acc_clean:.4f}\")\n",
    "\n",
    "# ========== Evaluate Pocket PLA ==========\n",
    "logger.info(\"=== Evaluating Pocket PLA ===\")\n",
    "cm_pocket, acc_pocket, sens_pocket = evaluate_model(\n",
    "    model=pocket_perceptron, \n",
    "    X=X_test, \n",
    "    y=y_test, \n",
    "    classes=classes, \n",
    "    plot_dir=plot_dir_pocket\n",
    ")\n",
    "print(f\"[POCKET] Accuracy: {acc_pocket:.4f}\")\n",
    "\n",
    "# ================== Plot Training Error Curves ==================\n",
    "def aggregate_iteration_losses(mcp):\n",
    "    \"\"\"\n",
    "    Aggregates iteration-level train/test losses across all digits\n",
    "    into an overall 'train_curve' and 'test_curve' by averaging.\n",
    "    \"\"\"\n",
    "    num_classes = mcp.num_classes\n",
    "    max_len = 0\n",
    "    for cls_idx in range(num_classes):\n",
    "        length_i = len(mcp.loss_history[cls_idx][\"train\"])\n",
    "        if length_i > max_len:\n",
    "            max_len = length_i\n",
    "    \n",
    "    all_train = []\n",
    "    for cls_idx in range(num_classes):\n",
    "        t_arr = mcp.loss_history[cls_idx][\"train\"][:]\n",
    "        \n",
    "        # If the classifier converged earlier, pad with the last value\n",
    "        if len(t_arr) < max_len and len(t_arr) > 0:\n",
    "            t_arr += [t_arr[-1]] * (max_len - len(t_arr))\n",
    "        elif len(t_arr) == 0:\n",
    "            t_arr = [0] * max_len\n",
    "        \n",
    "        all_train.append(t_arr)\n",
    "    \n",
    "    all_train = np.array(all_train)  # shape (num_classes, max_len)\n",
    "    train_curve = np.mean(all_train, axis=0)  # shape (max_len,)\n",
    "\n",
    "    return train_curve\n",
    "\n",
    "logger.info(\"=== Plotting Average Training Curves for Clean vs Pocket PLA ===\")\n",
    "\n",
    "clean_train_curve = aggregate_iteration_losses(clean_perceptron)\n",
    "pocket_train_curve = aggregate_iteration_losses(pocket_perceptron)\n",
    "\n",
    "plot_error_curves(\n",
    "    train_curve=clean_train_curve, \n",
    "    test_curve=pocket_train_curve,\n",
    "    title=\"Clean PLA vs. Pocket PLA (Avg. Train Error)\",\n",
    "    save_path=\"results/perceptron_results/train_curve_comparison.png\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Training Error Curves\n",
    "\n",
    "Each digit-specific classifier within `MultiClassPerceptron` stores iteration-level training errors. We'll **aggregate** them across all digits to create an average training curve. This provides a high-level overview of how the algorithm's error evolves over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logger.config import logger\n",
    "from core.analysis.plotting import plot_error_curves\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_iteration_losses(mcp):\n",
    "    \"\"\"\n",
    "    Aggregates iteration-level train/test losses across all digits\n",
    "    into an overall 'train_curve' and 'test_curve' by averaging.\n",
    "    \"\"\"\n",
    "    num_classes = mcp.num_classes\n",
    "    \n",
    "    # Find the max iteration length among all digits\n",
    "    max_len = 0\n",
    "    for cls_idx in range(num_classes):\n",
    "        length_i = len(mcp.loss_history[cls_idx][\"train\"])\n",
    "        if length_i > max_len:\n",
    "            max_len = length_i\n",
    "    \n",
    "    # Pad and sum\n",
    "    all_train = []\n",
    "    for cls_idx in range(num_classes):\n",
    "        t_arr = mcp.loss_history[cls_idx][\"train\"][:]\n",
    "        \n",
    "        # If the classifier converged earlier, pad with last value\n",
    "        if len(t_arr) < max_len:\n",
    "            t_arr += [t_arr[-1]] * (max_len - len(t_arr))\n",
    "        \n",
    "        all_train.append(t_arr)\n",
    "    \n",
    "    # Convert to numpy, compute mean\n",
    "    all_train = np.array(all_train)  # shape (num_classes, max_len)\n",
    "    train_curve = np.mean(all_train, axis=0)  # shape (max_len,)\n",
    "\n",
    "    # Return average train curve (No test curve stored in this example)\n",
    "    return train_curve\n",
    "\n",
    "logger.info(\"=== Plotting Average Training Curves for Clean vs Pocket PLA ===\")\n",
    "\n",
    "clean_train_curve = aggregate_iteration_losses(clean_perceptron)\n",
    "pocket_train_curve = aggregate_iteration_losses(pocket_perceptron)\n",
    "\n",
    "plot_error_curves(\n",
    "    train_curve=clean_train_curve, \n",
    "    test_curve=pocket_train_curve,\n",
    "    title=\"Clean PLA vs. Pocket PLA (Avg. Train Error)\",\n",
    "    save_path=\"results/perceptron_results/train_curve_comparison.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results Summary\n",
    "\n",
    "| Metric                           | PLA Clean         | PLA Pocket        |\n",
    "|----------------------------------|-------------------|-------------------|\n",
    "| **Overall Accuracy**             | [acc_clean *100]% | [acc_pocket *100]%|\n",
    "| **Average Sensitivity (TPR)**    | [Mean of sens_clean]% | [Mean of sens_pocket]% |\n",
    "\n",
    "### Observations:\n",
    "- Pocket PLA generally maintains or improves performance thanks to storing the best weights.\n",
    "- Both methods converged relatively quickly for MNIST data, indicating near-linearly separable conditions for many digits.\n",
    "- Additional improvements might come from more advanced methods or hyperparameter tuning.\n",
    "\n",
    "### Recommendations for Future Work:\n",
    "- Investigate performance for different max_iter or alternative update rules.\n",
    "- Compare results with logistic or linear regression on the same dataset.\n",
    "- Evaluate the effect of noise or partial occlusion on classification robustness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
